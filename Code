import pandas as pd
import numpy as np
import csv
import matplotlib.pylab as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score
from scipy import stats
import scipy.cluster.hierarchy as sch 
import warnings
import scipy.cluster.hierarchy as shc
warnings.filterwarnings('ignore')


#load in data
data = pd.read_csv('/Users/evanchinn/Downloads/CreditCardCustomerData.csv')
data.head()

#check info of data
data.info()

###no missing values >> Find unique values
data.nunique()


###Repeated values in customer key (5)

#Find and print duplicate keys
dupKeys = data[data.duplicated('Customer Key')]
print(dupKeys)

#remove duplicates
data = data.drop_duplicates(subset='Customer Key', keep='first')

data.drop(columns = ['Sl_No', 'Customer Key'], inplace = True)

#see duplicated rows
data[data.duplicated()]

#drop duplicated rows
data = data[~data.duplicated()]

#see the clean data (AKA no duplicates)
data.shape

#Visualization
for col in data.columns:
    print(col)
    print('Skew :',round(data[col].skew(),2))
    plt.figure(figsize=(15,4)) #width, height
    plt.subplot(1,2,1) #rows, columns, index
    data[col].hist(bins=10, grid=False)
    plt.ylabel('count')
    plt.subplot(1,2,2)
    sns.boxplot(x=data[col])
    plt.show()

plt.figure(figsize=(8,8))
sns.heatmap(data.corr(), annot=True, fmt='0.2f')
plt.show()

scaler = StandardScaler()
data_scaled = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)

data_scaled.head()

sse = {} 

for i in range(1, 10):
    kmeans = KMeans(n_clusters=i, max_iter=1000, random_state=1).fit(data_scaled)
    sse[i] = kmeans.inertia_

plt.figure()
plt.plot(list(sse.keys()), list(sse.values()), 'bx-')
plt.xlabel("Number of cluster")
plt.ylabel("SSE")
plt.show()

kmean = KMeans(n_clusters = 3, init = 'k-means++', random_state = 43)
kmean.fit(data_scaled)
y = kmean.predict(data_scaled)
silhouette_score(data_scaled, y)

#Not negative, correct cluster


sns.pairplot(data)

sc=StandardScaler()# scaling of data
scaled=sc.fit_transform(data)
scaled_data=pd.DataFrame(scaled,columns=data.columns)

plt.figure(figsize=(8,6))
sns.scatterplot(data=data,y='Avg_Credit_Limit',x='Total_Credit_Cards')
plt.show()
# the higher the avg_credit_limit, the higher is total_credit_card aquired by customer

plt.figure(figsize=(8,6))
sns.scatterplot(data=data,y='Avg_Credit_Limit',x='Total_visits_online')
plt.show()
# the greater the avg_credit_limit, the more frequently the customer visits (6-15)

plt.figure(figsize=(8,6))
sns.scatterplot(data=data,x='Total_calls_made',y='Total_Credit_Cards')




plt.figure(figsize=(10,8))
dend=shc.dendrogram(shc.linkage(scaled_data,method='ward'))
plt.title('Dendrogram')
plt.xlabel('Customers')
plt.ylabel('Euclidean distances')
plt.show()




